

install.packages("ROAuth")        
install.packages("twitteR")      
install.packages("tm")            
install.packages("wordcloud")     
install.packages("ggplot2")      
install.packages("RColorBrewed")  
install.packages("stringr")      
install.packages("dplyr")        
install.packages("tidytext")      
install.packages("readr")         




library(ROAuth)
library(twitteR)
library(tm)
library(wordcloud)
library(ggplot2)
library(Rcolor)
library(stringr)
library(dplyr)
library(tidytext)
library(readr)
library(stringi)



api_key <- "BYmncKtg8MUZsPXpFTEAS0bHx"
api_secret_key <- "ZSJWYu9pqYQaiucxIAvMtlTqJpYgyHHjjZYcWlv2e3W2oIXSdN"
access_token <- "1296063762-nj6uf0ZwXLwbs1dsDIRjK7M4MD9jEwxUmsn4wjn"
access_token_secret <- "ImNl6rW0zyHLZ7xTmHSzwyx8xj28TLUx2B3pgmuOlm3IL"

setup_twitter_oauth(api_key,api_secret_key,access_token,access_token_secret)


ebayData <- searchTwitteR('@eBay', n = 10000, lang="en") 




save(ebayData, file="ebayData.RData") #Data Kaydedilir.
length(ebayData)

head(ebayData)

#Corpus Oluşturma İşlemi

ebayData.text <- sapply(ebayData, function(x) x$getText())
mycorpus <- Corpus(VectorSource(ebayData.text))





removeURL <- function(x) gsub("http[[:alnum:]]*","",x)
removeNumPuncts <- function(x) gsub("[^[:alpha:][:space:]]*","",x)



rmv_word <- c(stopwords("en"))

rmv_word


clean_corp <- tm_map(mycorpus, PlainTextDocument)
clean_corp <- tm_map(clean_corp, content_transformer(removeURL))
clean_corp <- tm_map(clean_corp, stripWhitespace)
clean_corp <- tm_map(clean_corp, content_transformer(tolower))
clean_corp <- tm_map(clean_corp, removeWords, rmv_word)
clean_corp <- tm_map(clean_corp, content_transformer(removeNumPuncts))
clean_corp <- tm_map(clean_corp, removePunctuation)

ebayData.text[10] #Verinin temizlenmemiş hali.



clean_corp[[10]][1] #Verinin temizlenmiş hali.


#Terim Dökümantasyon Değerleri
ebayData_tdm <- TermDocumentMatrix(clean_corp)
ebayData_tdm


#matrix oluşturma
ebayData_m <- as.matrix(ebayData_tdm)
dim(ebayData_m)



term_freq <- rowSums(ebayData_m)
term_freq <- sort(term_freq, decreasing = TRUE)

term_freq[1:10] #10 tane veriyi getirdik.


#Grafik halinde görelim
barplot(term_freq[1:10], col="tan", las=2)


#Frekansı 300 ve daha üzeri olan kelimelerin grafiği
term_freq <- subset(term_freq, term_freq >=300)
term_freqs_df <- data.frame(term= names(term_freq), freq= term_freq)
ggplot(term_freqs_df, aes(x=term, y=freq)) + 
  geom_line(aes(group=1), colour="salmon3")+
  geom_point(size=3, colour="pink2") + xlab("kelime") + ylab("Frekans") + coord_flip()



wordcloud(clean_corp, min.freq = 2, scale =c(2,0.5),colors = brewer.pal(8,"Dark2"),
          random.color = TRUE, random.order = FALSE, max.words = 200)


#Frekansa göre kelime bulutu oluşturma
word_freqs <- data.frame(term_freq, term = names(term_freq), num= term_freq)
wordcloud(word_freqs$term, word_freqs$num, max.words = 200, colors=brewer.pal(11,"RdYlGn"),random.color = TRUE)




findAssocs(ebayData_tdm, terms="cargo",corlimit = 0.5)

































































